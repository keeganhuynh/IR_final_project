{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31313,"status":"ok","timestamp":1706294635045,"user":{"displayName":"Crisstan Huynh","userId":"09496431270907216431"},"user_tz":-420},"id":"tAHBfTrg98jk","outputId":"eb14a004-2f4d-4d54-a8a6-77598f6c4f95"},"outputs":[{"name":"stderr","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"c:\\Users\\Hoang\\Code\\IR project\\IR_final_project\\composed_image_retrieval\\demo.py\", line 21, in <module>\n","    import torch\n","ModuleNotFoundError: No module named 'torch'\n"]}],"source":["!python composed_image_retrieval/demo.py \\\n","    --openai-pretrained \\\n","    --resume \"../pic2word_model.pt\" \\\n","    --retrieval-data \"cirr\" \\\n","    --query_file \"composed_image_retrieval\\data\\cirr\\img_raw\\dev\\dev-244-0-img0.png\" \\\n","    --prompts \"show three bottles of soft drink\" \\\n","    --demo-out \"./demo-out\" \\\n","    --gpu 0 \\\n","    --model ViT-L/14"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":373147,"status":"ok","timestamp":1706326332435,"user":{"displayName":"Crisstan Huynh","userId":"09496431270907216431"},"user_tz":-420},"id":"tQJtH6N9DntR","outputId":"7369b0cc-527d-45e3-dd9f-f6b8b813cb04"},"outputs":[{"name":"stdout","output_type":"stream","text":["2024-01-27 03:26:03.282543: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-01-27 03:26:03.282594: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-01-27 03:26:03.283980: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-01-27 03:26:03.291209: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-01-27 03:26:04.418339: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Đường dẫn hiện tại của file: /content/drive/MyDrive/Information Retrieval/composed_image_retrieval/model\n","2024-01-27,03:26:07 | INFO | Rank 0 | Params:\n","2024-01-27,03:26:07 | INFO | Rank 0 | C: 3.16\n","2024-01-27,03:26:07 | INFO | Rank 0 | aggregate: True\n","2024-01-27,03:26:07 | INFO | Rank 0 | batch_size: 64\n","2024-01-27,03:26:07 | INFO | Rank 0 | beta1: 0.9\n","2024-01-27,03:26:07 | INFO | Rank 0 | beta2: 0.98\n","2024-01-27,03:26:07 | INFO | Rank 0 | checkpoint_path: ./logs/lr=0.0005_wd={args.wd}_agg={args.aggregate}_model={args.model}_batchsize={args.batch_size}_workers={args.workers}_date=2024-01-27-03-26-07/checkpoints\n","2024-01-27,03:26:07 | INFO | Rank 0 | copy_codebase: False\n","2024-01-27,03:26:07 | INFO | Rank 0 | csv_caption_key: title\n","2024-01-27,03:26:07 | INFO | Rank 0 | csv_img_key: filepath\n","2024-01-27,03:26:07 | INFO | Rank 0 | csv_separator: \t\n","2024-01-27,03:26:07 | INFO | Rank 0 | dataset_type: auto\n","2024-01-27,03:26:07 | INFO | Rank 0 | dataset_type_val: auto\n","2024-01-27,03:26:07 | INFO | Rank 0 | debug: False\n","2024-01-27,03:26:07 | INFO | Rank 0 | demo_out: demo\n","2024-01-27,03:26:07 | INFO | Rank 0 | dist_backend: nccl\n","2024-01-27,03:26:07 | INFO | Rank 0 | dist_url: tcp://127.0.0.1:6100\n","2024-01-27,03:26:07 | INFO | Rank 0 | distributed: False\n","2024-01-27,03:26:07 | INFO | Rank 0 | dp: False\n","2024-01-27,03:26:07 | INFO | Rank 0 | droprate: 0.1\n","2024-01-27,03:26:07 | INFO | Rank 0 | epochs: 32\n","2024-01-27,03:26:07 | INFO | Rank 0 | eps: 1e-06\n","2024-01-27,03:26:07 | INFO | Rank 0 | eval_mode: cirr_test\n","2024-01-27,03:26:07 | INFO | Rank 0 | gpu: 0\n","2024-01-27,03:26:07 | INFO | Rank 0 | imagenet_v2: None\n","2024-01-27,03:26:07 | INFO | Rank 0 | imagenet_val: None\n","2024-01-27,03:26:07 | INFO | Rank 0 | log_level: 20\n","2024-01-27,03:26:07 | INFO | Rank 0 | log_path: ./logs/lr=0.0005_wd={args.wd}_agg={args.aggregate}_model={args.model}_batchsize={args.batch_size}_workers={args.workers}_date=2024-01-27-03-26-07/out.log\n","2024-01-27,03:26:07 | INFO | Rank 0 | logs: ./logs/\n","2024-01-27,03:26:07 | INFO | Rank 0 | lr: 0.0005\n","2024-01-27,03:26:07 | INFO | Rank 0 | middle_dim: 512\n","2024-01-27,03:26:07 | INFO | Rank 0 | model: ViT-L/14\n","2024-01-27,03:26:07 | INFO | Rank 0 | multigpu: None\n","2024-01-27,03:26:07 | INFO | Rank 0 | n_layer: 2\n","2024-01-27,03:26:07 | INFO | Rank 0 | name: lr=0.0005_wd={args.wd}_agg={args.aggregate}_model={args.model}_batchsize={args.batch_size}_workers={args.workers}_date=2024-01-27-03-26-07\n","2024-01-27,03:26:07 | INFO | Rank 0 | ngpus_per_node: 1\n","2024-01-27,03:26:07 | INFO | Rank 0 | openai_pretrained: True\n","2024-01-27,03:26:07 | INFO | Rank 0 | precision: amp\n","2024-01-27,03:26:07 | INFO | Rank 0 | prompts: None\n","2024-01-27,03:26:07 | INFO | Rank 0 | query_file: None\n","2024-01-27,03:26:07 | INFO | Rank 0 | rank: 0\n","2024-01-27,03:26:07 | INFO | Rank 0 | regression_frequency: 2\n","2024-01-27,03:26:07 | INFO | Rank 0 | report_to: \n","2024-01-27,03:26:07 | INFO | Rank 0 | resume: /content/drive/MyDrive/Information Retrieval/pic2word_model.pt\n","2024-01-27,03:26:07 | INFO | Rank 0 | retrieval_data: None\n","2024-01-27,03:26:07 | INFO | Rank 0 | save_frequency: 1\n","2024-01-27,03:26:07 | INFO | Rank 0 | save_most_recent: False\n","2024-01-27,03:26:07 | INFO | Rank 0 | skip_aggregate: False\n","2024-01-27,03:26:07 | INFO | Rank 0 | skip_scheduler: False\n","2024-01-27,03:26:07 | INFO | Rank 0 | source_data: None\n","2024-01-27,03:26:07 | INFO | Rank 0 | target_data: None\n","2024-01-27,03:26:07 | INFO | Rank 0 | target_pad: False\n","2024-01-27,03:26:07 | INFO | Rank 0 | tensorboard: False\n","2024-01-27,03:26:07 | INFO | Rank 0 | tensorboard_path: \n","2024-01-27,03:26:07 | INFO | Rank 0 | time_suffix: True\n","2024-01-27,03:26:07 | INFO | Rank 0 | train_data: None\n","2024-01-27,03:26:07 | INFO | Rank 0 | use_bn_sync: False\n","2024-01-27,03:26:07 | INFO | Rank 0 | use_debiased_sampler: False\n","2024-01-27,03:26:07 | INFO | Rank 0 | use_prefix: False\n","2024-01-27,03:26:07 | INFO | Rank 0 | val_data: None\n","2024-01-27,03:26:07 | INFO | Rank 0 | wandb: False\n","2024-01-27,03:26:07 | INFO | Rank 0 | wandb_notes: \n","2024-01-27,03:26:07 | INFO | Rank 0 | warmup: 10000\n","2024-01-27,03:26:07 | INFO | Rank 0 | wd: 0.2\n","2024-01-27,03:26:07 | INFO | Rank 0 | workers: 1\n","2024-01-27,03:26:07 | INFO | Rank 0 | world_size: 1\n","2024-01-27,03:26:07 | INFO | Rank 0 | zeroshot_frequency: 2\n","2024-01-27,03:26:07 | INFO | Rank 0 | Use GPU: 0 for training\n","2024-01-27,03:26:20 | INFO | Rank 0 | => loaded checkpoint '/content/drive/MyDrive/Information Retrieval/pic2word_model.pt' (epoch 30)\n","/content/drive/MyDrive/Information Retrieval/composed_image_retrieval/data\n","2024-01-27,03:26:20 | INFO | Rank 0 | Use 4148 imgs\n","2024-01-27,03:26:20 | INFO | Rank 0 | Use 2315 imgs\n","100% 37/37 [01:46<00:00,  2.87s/it]\n","100% 65/65 [03:56<00:00,  3.64s/it]\n","Exception in thread Thread-1 (_monitor):\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.10/logging/handlers.py\", line 1556, in _monitor\n","    record = self.dequeue(True)\n","  File \"/usr/lib/python3.10/logging/handlers.py\", line 1505, in dequeue\n","    return self.queue.get(block)\n","  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 103, in get\n","    res = self._recv_bytes()\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n","    buf = self._recv_bytes(maxlength)\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n","    buf = self._recv(4)\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 383, in _recv\n","    raise EOFError\n","EOFError\n"]}],"source":["!python eval_retrieval.py \\\n","    --openai-pretrained \\\n","    --resume \"/content/drive/MyDrive/Information Retrieval/pic2word_model.pt\" \\\n","    --eval-mode \"cirr_test\" \\\n","    --gpu 0 \\\n","    --model ViT-L/14"]},{"cell_type":"markdown","metadata":{"id":"Ef3bkL_Zybxr"},"source":["# Unzip"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2365534,"status":"ok","timestamp":1706323546443,"user":{"displayName":"Crisstan Huynh","userId":"09496431270907216431"},"user_tz":-420},"id":"8if1a0WED8eW","outputId":"527ba0eb-e84a-406f-d707-cbbebd4a2526"},"outputs":[{"name":"stdout","output_type":"stream","text":["Contents of /content/drive/MyDrive/Information Retrieval/composed_image_retrieval/data/CIRR/test1_img.zip have been successfully extracted to /content/drive/MyDrive/Information Retrieval/composed_image_retrieval/data/CIRR/\n"]}],"source":["import zipfile\n","import os\n","\n","# Specify the path to the zip file\n","zip_file_path = \"/content/drive/MyDrive/Information Retrieval/composed_image_retrieval/data/CIRR/test1_img.zip\"\n","\n","# Specify the directory where you want to extract the contents\n","extracted_dir = \"/content/drive/MyDrive/Information Retrieval/composed_image_retrieval/data/CIRR/\"\n","\n","# Open the zip file\n","with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n","    # Extract all the contents into the specified directory\n","    zip_ref.extractall(extracted_dir)\n","\n","print(f\"Contents of {zip_file_path} have been successfully extracted to {extracted_dir}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oGLoqXhcKzuA"},"outputs":[],"source":["import os\n","\n","# Đường dẫn đến thư mục\n","folder_path = \"/content/drive/MyDrive/Information Retrieval/composed_image_retrieval/data/CIRR/raw_images/dev\"\n","\n","count = 0\n","for filename in os.listdir(folder_path):\n","    file_path = os.path.join(folder_path, filename)\n","    if os.path.isfile(file_path):\n","        count += 1\n","count"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aAIlOMLFM-fZ"},"outputs":[],"source":["import torch\n","a = torch.tensor([True, True, False])\n","b = torch.tensor([1, 2, 3])\n","b = b[a]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":375,"status":"ok","timestamp":1706291426495,"user":{"displayName":"Crisstan Huynh","userId":"09496431270907216431"},"user_tz":-420},"id":"_-HZwR3W3h2c","outputId":"950737d6-4cfd-46b7-f9d8-d20aba0f20f8"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(False)\n","tensor(False)\n","tensor(True)\n"]}],"source":["for i in a:\n","  print(i == False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":404,"status":"ok","timestamp":1706292732718,"user":{"displayName":"Crisstan Huynh","userId":"09496431270907216431"},"user_tz":-420},"id":"ym1P4MCn3uiv","outputId":"e96360c9-2f79-48ba-a50f-a995d88f3433"},"outputs":[{"data":{"text/plain":["(array([2]),)"]},"execution_count":74,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","np.where(~a)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMfg4cRB5R0HPa6saxVxncu","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":0}
